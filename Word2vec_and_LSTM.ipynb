{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtSSju7cEYdG",
        "outputId": "d3e9685c-1a06-4520-c4f3-bb16c6a12b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.3.0 in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: torchtext==0.18.0 in /usr/local/lib/python3.10/dist-packages (0.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext==0.18.0) (12.6.85)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.18.0) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchtext==0.18.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchtext==0.18.0) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.3.0\n",
        "!pip install torchtext==0.18.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnXCMDWz7XR-",
        "outputId": "db757548-bdfe-4804-c3af-ca3f7794f0ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import sklearn as sk\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "import torchtext.vocab as tvc\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7oxskrGvW7e",
        "outputId": "e7e1ff63-31e9-47b7-eb83-c7d2e1dfeb2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\linhn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\linhn\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xQ58myZlDY_-"
      },
      "outputs": [],
      "source": [
        "#load Training Data\n",
        "data = pd.read_csv(\"sample_data/labeled_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9Q4T-VUs9NcN"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "\n",
        "wordnet = WordNetLemmatizer()\n",
        "stop_words = stopwords.words('english')\n",
        "def clean_data(text, stop_words, max_length):\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"'\",\"\")\n",
        "  text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "  text = text.split()\n",
        "  text = [word for word in text if word not in stop_words]\n",
        "  text = [wordnet.lemmatize(word) for word in text]\n",
        "  text = text[:max_length]\n",
        "  return text\n",
        "\n",
        "data[\"tweet\"] = data[\"tweet\"].apply(clean_data, stop_words = stop_words, max_length = 1000)\n",
        "dataset_y = data[\"class\"].tolist()\n",
        "dataset_x = data[\"tweet\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "85T03iW4DY__"
      },
      "outputs": [],
      "source": [
        "#Create training sets\n",
        "\n",
        "X_train = dataset_x\n",
        "Y_train = dataset_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3f_ctQO0O1hH"
      },
      "outputs": [],
      "source": [
        "#Build/Load the Vocabulary\n",
        "\n",
        "min_freq = 2\n",
        "unk_token = \"<unk>\"\n",
        "pad_token = \"<pad>\"\n",
        "special_tokens = [unk_token, pad_token]\n",
        "special_tokens_output = []\n",
        "\n",
        "Y_train = np.array(Y_train).reshape(-1,1)\n",
        "if torch.load('vocabulary_hate_speech.pt') == None:\n",
        "    input_train_dataset = tvc.build_vocab_from_iterator(X_train, min_freq = min_freq, specials = special_tokens)\n",
        "    torch.save(input_train_dataset, 'vocabulary_hate_speech.pt')\n",
        "else:\n",
        "    input_train_dataset = torch.load('vocabulary_hate_speech.pt')\n",
        "input_train_dataset.set_default_index(input_train_dataset[unk_token])\n",
        "Y_train = Y_train.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "otA4PoROULzw"
      },
      "outputs": [],
      "source": [
        "#Numerize Inputs and Outputs and Pad Inputs\n",
        "\n",
        "for i in range(len(Y_train)):\n",
        "  X_train[i] = torch.tensor(input_train_dataset.lookup_indices(X_train[i]))\n",
        "X_train = nn.utils.rnn.pad_sequence(X_train, padding_value = 0, batch_first = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ON7G_FtzVAP9"
      },
      "outputs": [],
      "source": [
        "#Merge X, Y into a dataset and divide into batches with 32 samples in each batch\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, x, y):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "  def __len__(self):\n",
        "    return len(self.x)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.x[idx], self.y[idx]\n",
        "data = CustomDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(data, batch_size = 32, shuffle = True, num_workers = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Iq68t8h4Y3lT"
      },
      "outputs": [],
      "source": [
        "#Build the Encoder Model\n",
        "\n",
        "class Encode(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, num_layers,embedding_size, dropout):\n",
        "    super(Encode, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers, batch_first = True, dropout = dropout)\n",
        "    self.ReLU = nn.ReLU()\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "    self.fc1 = nn.Linear(31, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    output, (hidden, cell) = self.lstm(embedding)\n",
        "    output = self.fc(output)\n",
        "    print(output.shape)\n",
        "    out = self.fc1(output.reshape(-1,31))\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "v5Y4YY0SfhYO"
      },
      "outputs": [],
      "source": [
        "#Initialize model, loss, and optimizer function\n",
        "\n",
        "input_size = len(input_train_dataset)\n",
        "hidden_size = 100\n",
        "output_size = 1\n",
        "num_layers = 2\n",
        "embedding_size = 128\n",
        "dropout = 0.5\n",
        "\n",
        "model = Encode(input_size, hidden_size, output_size, num_layers, embedding_size, dropout)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fVsWCQnX7XjZ"
      },
      "outputs": [],
      "source": [
        "#Load Model Checkpoint\n",
        "\n",
        "check_point = torch.load(\"check-point-hate-speech.pt\")\n",
        "model.load_state_dict(check_point['model_state_dict'])\n",
        "optimizer.load_state_dict(check_point['optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVyDwA4veckQ"
      },
      "outputs": [],
      "source": [
        "#Train model\n",
        "\n",
        "num_epochs = 20\n",
        "valid_loss = 0\n",
        "count = 0\n",
        "for epoch in range(num_epochs):\n",
        "  for input, output in dataloader:\n",
        "    output = output[0]\n",
        "    y_pred = model(input)\n",
        "    l = loss(y_pred, output)\n",
        "    valid_loss += l.item()\n",
        "    count += 1\n",
        "    l.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    print(f\"Epoch: {epoch}, Loss: {valid_loss/float(count)}\")\n",
        "    if count % 100 == 0:\n",
        "      torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                }, \"check-point.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JhddyqnXuzKg"
      },
      "outputs": [],
      "source": [
        "#Load, Clean, and Divide test file into X_test and Y_test\n",
        "\n",
        "data_test = pd.read_csv(\"sample_data/testhatespeech.csv\")\n",
        "data_test[\"tweet\"] = data_test[\"tweet\"].apply(clean_data, stop_words = stop_words, max_length = 1000)\n",
        "def minimize(text, max_length):\n",
        "  text = text[:max_length]\n",
        "  return text\n",
        "data_test[\"tweet\"] = data_test[\"tweet\"].apply(minimize, max_length = 31)\n",
        "X_test = data_test[\"tweet\"].tolist()\n",
        "Y_test = data_test[\"Toxicity\"].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Flan_AkuYkn3"
      },
      "outputs": [],
      "source": [
        "#Numberize and Pad\n",
        "\n",
        "Y_test = np.array(Y_test).reshape(-1,1)\n",
        "Y_test = Y_test.tolist()\n",
        "for j in range(len(X_test)):\n",
        "  X_test[j] = torch.tensor(input_train_dataset.lookup_indices(X_test[j]))\n",
        "X_test = nn.utils.rnn.pad_sequence(X_test, padding_value = 0, batch_first = True)\n",
        "Y_test = torch.tensor(Y_test, dtype = torch.float32)\n",
        "Y_test = Y_test.reshape(-1).int()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "usn8qCdkDZAF"
      },
      "outputs": [],
      "source": [
        "new_data = []\n",
        "for m in range(X_test.shape[0]):\n",
        "    new_tensor = torch.cat((X_test[m], torch.zeros(31 - X_test[m].shape[0]))).int()\n",
        "    new_data.append(new_tensor)\n",
        "X_test = torch.stack(new_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWdgO-Ji6XjM",
        "outputId": "93c5ec26-6527-4943-ab0d-08cbd2dae018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3554, 31, 1])\n",
            "The accuracy of the model through testing: 77.13080048561096%\n"
          ]
        }
      ],
      "source": [
        "#Conduct Model Testing\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred_cls = torch.max(y_pred,1)\n",
        "  for i in range (y_pred_cls.indices.shape[0]):\n",
        "    if y_pred_cls.indices[i] == 2:\n",
        "      y_pred_cls.indices[i] = 0\n",
        "  acc = y_pred_cls.indices.eq(Y_test).sum() / float(3555)\n",
        "  print(f\"The accuracy of the model through testing: {acc.item()*100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKxdcs_ZdUGo",
        "outputId": "04327454-7e09-4589-ad27-57b41445dca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(2)\n"
          ]
        }
      ],
      "source": [
        "#Model Testing by Inputs from Keyboard\n",
        "\n",
        "nlp_input = \"I love this movie guys\"\n",
        "nlp_input = clean_data(nlp_input, stop_words, 1000)\n",
        "input = input_train_dataset.lookup_indices(nlp_input)\n",
        "for m in range(31 - len(nlp_input)):\n",
        "  input.append(0)\n",
        "with torch.no_grad():\n",
        "  input = torch.tensor(input)\n",
        "  input = input.reshape(-1,31)\n",
        "  print(torch.argmax(model(input)))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
